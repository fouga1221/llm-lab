# プロジェクト要件定義: オンラインゲームNPC自然会話用ローカルLLM

## 1. 背景と目的
- オンラインゲームのNPCが自然な対話を行い、会話内容に応じてゲーム状態を更新するための「コード断片/関数呼び出し案」を返却できるローカルLLMの実現と、コスト対効果と十分な対話性能の両立を検証する。
- どのモデルにどの調整（量子化、微調整、プロンプト戦略、整形式出力制約など）を施すと、品質・レイテンシ・コストの均衡が取れるかを体系的に評価する。

## 2. スコープ
### 2.1 対象範囲
- ローカル環境で動作する会話LLMの選定・チューニング・評価。
- NPC対話に特化したプロンプト/システムプロンプト設計、ペルソナ・世界観・会話記憶の取り扱い。
- ゲーム状態更新のための「関数呼び出し（ツール呼び出し）/コード断片提案」機能と、その出力の整形式化（JSON/スキーマ）。
- ゲームエンジン連携用アダプタのI/F定義（Unity/Unreal/独自サーバなどに接続可能な抽象I/F）。
- 自動/半自動評価基盤（対話品質、ツール呼び出し正確性、構造出力妥当性、レイテンシ、メモリ使用量、コスト試算）。

### 2.2 非対象
- 実ゲームクライアント実装の全面開発（最小限のアダプタ/スタブは実装）。
- オンライン推論（クラウドAPI）の本番運用設計（ローカルLLM中心）。
- 生成コードの自動実行（提案までは行うが、実行はサンドボックス越しの明示承認が必要）。

## 3. 成果物・ゴール・KPI
- 成果物
  - ローカルLLM推論サーバ/ランナー、会話管理、ツール呼び出しI/F、検証スクリプト、評価レポート。
  - プロンプトテンプレート、関数呼び出しスキーマ、RAG/記憶モジュール（必要に応じて）。
  - 比較表（モデル×調整手法×品質/コスト/レイテンシ）。
- KPI（例）
  - ツール呼び出し正確性（関数名・必須引数の完全一致率）≥ 90%。
  - 構造出力（JSON）妥当性率 ≥ 99%。
  - 1往復対話のP95レイテンシ ≤ 800ms（7B/8BクラスGPU時の目安、CPU時は別基準）。
  - トークン当たりコスト（電力/時間）をベースライン比で30%以上削減。
  - 人手評価による対話自然性スコア（5段階）≥ 4.0。

## 4. 利用者/関係者
- ゲームサーバ/クライアント開発者：API/アダプタ経由でLLMを組み込み。
- ゲームデザイナ/ライター：NPCペルソナ/世界観/台本の提供と評価。
- ML/LLMエンジニア：モデル選定、チューニング、評価の実施。
- プロデューサ/PM：コスト・スケジュール管理、品質ゲート設定。

## 5. 機能要件
### 5.1 会話・対話管理
- ペルソナ/役割/口調/禁則事項を含むシステムプロンプト適用。
- マルチターン対話の文脈維持（要約ベースの短期記憶＋外部記憶/RAG）。
- 日本語優先、英語混在にも耐える多言語ハンドリング。
- 温度や最大トークンなどの推論パラメータを会話単位で調整可能。

### 5.2 コード断片/関数呼び出し提案（ツール呼び出し）
- 必ずJSONスキーマに適合した整形式で提案（関数名、引数、根拠、危険度）。
- 提案は「実行候補」であり、実行は別プロセスのバリデータ/承認フローを経る。
- サポートする関数リスト/シグネチャはゲーム側から提供（RAGまたはメタデータ）。
- 複数候補のランキング/自己検証（self-check）と失敗時の代替案提示。

### 5.3 ゲームエンジン連携
- HTTP/gRPC/WebSocket等で疎結合連携。I/Fは言語非依存。
- 最低限のアダプタ層（Game Engine Adapter）を提供：
  - `propose_action`（関数候補作成）、`explain_action`（説明/根拠）、`chat`（通常対話）。
- コマンド/関数のホワイトリスト制御、引数検証、スキーマ検証。

### 5.4 記憶/ナレッジ
- 世界観・NPC設定・クエスト進行などの知識ベース（ファイル/RAG）。
- 対話要約とエピソード記憶（DB/ベクタストア）を用いた文脈再構成。

### 5.5 評価・実験UI
- スクリプト/ノートブックで再現可能な評価パイプライン。
- 簡易Web UIまたはCLI（ログ閲覧、会話再生、メトリクス集計）。

## 6. 非機能要件
### 6.1 性能/レイテンシ
- ターゲット環境：ローカルGPU（8–24GB VRAM）またはCPU。
- 目安：7B/8BクラスでP95 ≤ 800ms（GPU）、CPUはP95 ≤ 2.5s。
- コンテキスト長：最低32k（要約/RAG併用）。
- ハードウェア別プロファイル（例）：
  - GPU 6–8GB: 7B 4bit量子化（GPTQ/AWQ/GGUF-EXL2）。
  - GPU 12–16GB: 7B FP16/8bit＋長コンテキスト、または14B 4bit。
  - GPU 24GB+: 14B 8bit/4bit高品質、必要に応じてMixture/70Bの上限評価。
  - CPUオンリー: GGUF（q4_K/q5_K）＋llama.cpp最適化、低スループット運用。

### 6.2 コスト/運用
- 量子化（GGUF/AWQ/GPTQ）でVRAM/メモリ削減、スループット最適化。
- モデル切替を容易にし、環境依存（GPU/CPU）を抽象化。
- オフライン運用（ネットワーク遮断）を前提としたモデル/辞書の配備。
- 電力・消費量（GPU/全体）を計測し、1トークン当たりコスト試算に反映。

### 6.3 信頼性/安全性
- 生成コードはデフォルト非実行。サンドボックス（権限最小化）で検証後に承認実行。
- プロンプトインジェクション/ツールインジェクション対策（システムプロンプト分離、スキーマ強制、定型検証）。
- ログの匿名化/PII削除、監査用イベントログ。

### 6.4 保守性/拡張性
- モジュラ設計（モデル、記憶、RAG、アダプタ、評価を疎結合）。
- コンフィグ駆動（YAML/JSON）。実験設定のトラッキング（seed, params, model）。

### 6.5 観測性
- メトリクス：レイテンシ、トークン/秒、失敗率、JSON妥当性率、ツール正確性。
- 構造化ログ（JSON Lines）。再現性のためのセッションID付与。
- トークン/秒はprefill/decodingを分離して記録。モデルID、量子化方式、コミットID、seed、推論設定をログに必須付与。

### 6.6 日本語品質
- 敬体/常体/口調を制御可能。ルビ/方言などは任意要件。

### 6.7 整形式出力の運用
- ストリーミングJSON整形式出力：逐次デコードに対してインクリメンタルにスキーマ検証を実施し、不正トークン検知時に再サンプル/リトライ。
- Grammar/JSON Schema拘束デコード（llama.cpp grammar/Outlines相当）を活用。

## 7. モデル候補と調整方針
### 7.1 モデル選定基準
- 日本語対話品質、ツール/関数呼び出し能力、コンテキスト長、VRAM要件、ライセンス、量子化適性、推論実装（llama.cpp/ollama/vLLM等）との相性。

### 7.2 候補モデル（例）
- Llama 3.1 8B/70B Instruct（多言語・ツール性能良）
- Qwen2.5 7B/14B Instruct（日本語強め、32k以上の長文対応）
- Mistral 7B Instruct / Mixtral 8x7B（速度/品質バランス）
- Phi-3.5/4-mini（軽量・コスパ重視、要日本語評価）

※ まずは7B/8Bクラス中心に比較、必要に応じて14B-70Bで上限評価。

### 7.3 調整手法
- 量子化：GGUF（llama.cpp/Ollama）、AWQ/GPTQ（GPU推論）。
- 微調整：LoRA/QLoRA（指示追従、ツール呼び出し強化、整形式出力強化）。
- 位置：継続事前学習（世界観/用語への適応）、SFT、DPO/ORPOで遵守性・低幻覚化。
- RAG：API仕様/世界観を外部知識として注入、retrieval-augmented function calling。

### 7.4 推論最適化
- サンプリング：`temperature`, `top_p`, `min_p`, `repetition_penalty`。
- KVキャッシュ、prefill/batching、speculative decoding（可能なら）。
- JSON/関数出力の構文制約（Grammar/JSON Schema/Function schemaによる拘束デコード）。

### 7.5 プロンプト戦略/整形式出力
- システムプロンプトにNPC役割・禁止事項・出力規約（必ずJSONで返す等）を明示。
- Few-shotで関数提案例・失敗例・セルフチェック手順を提示。
- 出力は「回答テキスト部」と「structured_actions部」を分離し、後者は厳格スキーマに準拠。

### 7.6 量子化/実装の推奨レシピ
- 量子化方式の比較観点：
  - GPTQ（ExLlamaV2最適化と相性良、7B 4bitの有力候補）
  - AWQ/AutoAWQ（PTQで速度/品質バランス）
  - GGUF/EXL2（llama.cpp系、CPU/軽GPUで有利）
- 推奨開始点：7B GPTQ-4bit + ExLlamaV2（GPU）または GGUF q4_K_M（CPU/軽GPU）。
- カーネル最適化：FlashAttention/SDPA、bitsandbytes 4/8bitロード、KVキャッシュ有効化。

## 8. アーキテクチャ案
### 8.1 コンポーネント
- Inference Runner（llama.cpp/ollama/vLLMのいずれか）
- Conversation Manager（履歴、要約、記憶/RAG）
- Tooling Manager（関数スキーマ配信、出力検証、ホワイトリスト）
- Game Engine Adapter（HTTP/gRPC）
- Validator/Sandbox（静的検査、実行前検証）
- Evaluator（自動/人手評価、ログ集計）
- Confidence Router/Cascade Orchestrator（低信頼時のみ上位モデルへフォールバック）

### 8.2 API I/F（例・要約）
- `POST /chat`: 入力テキスト→応答テキスト＋structured_actions
- `POST /propose_action`: 世界状態・入力→関数呼び出し候補
- `GET /schema/functions`: 利用可能な関数スキーマ取得

### 8.3 データフロー（簡略）
1) ゲーム→会話入力＋現在状態
2) 記憶/RAGで補助文脈構築→LLM推論
3) LLM出力（テキスト＋structured_actions）
4) Validatorでスキーマ/引数検証→アダプタ経由でゲームへ返却

### 8.4 出力ガードレール
- 生成ストリームに対するスキーマ検証を行い、逸脱時は自己修復プロンプト/自動リトライを適用。

## 9. データ/学習/評価
### 9.1 データ
- NPC対話（日本語中心）、ゲームAPI呼び出しトレース、世界観ドキュメント。
- 合成データ生成（スクリプト/Agentで関数呼び出し例を拡充）。
- 機密/PII除去、ライセンス確認、評価用holdoutセット分離。

### 9.2 評価指標
- 関数呼び出し正確性（関数名/必須引数の完全一致、型妥当性）。
- JSON整形式率（スキーマ検証成功率）。
- 目標達成率（対話シナリオでのクエスト進行/イベント発火の成功）。
- レイテンシ（P50/P95）、トークン/秒、メモリ使用量。
- 幻覚率（未定義関数の提案率）。
- 人手評価（自然性、一貫性、役割遵守）。

### 9.3 ベンチシナリオ（例）
- 会話だけでクエスト開始/受諾/達成/報酬受取。
- インベントリ操作（取得/消費/装備）。
- ワープ/移動/追従/会話分岐。
- コンバット支援（難易度に応じた行動提案）。

### 9.4 受入基準と採点ルーブリック
- Exit Criteria例：ツール正確性≥90%、JSON妥当性≥99%、P95レイテンシが目標内、目標達成率≥しきい値。
- 採点：関数名厳格一致＋必須引数の完全一致＋型妥当性。再試行を含む最終成功率も記録。
- ストレス/対逆攻：Jailbreak/誘導（Prompt Injection）、ノイズ文脈、未定義関数誘導への耐性評価。
- カスケード評価：7B単独 vs 7B→14BフォールバックのKPI（品質/レイテンシ/コスト）比較。

## 10. セキュリティ/法務
- 実行前のサンドボックス検証と明示承認。
- ホワイトリスト式ツール呼び出し、権限分離（read-onlyとstate-changingの分離）。
- ログの匿名化、第三者提供なし、オフライン前提運用。
- モデル/データのライセンス順守（商用可否、再配布条件の確認）。
- ツールI/O制限：外部ネット/ファイルアクセスはデフォルト拒否、ホワイトリストURI/パスのみ許可。SSRF対策としてスキーム/ホスト検証、引数エスケープ、タイムアウト設定。
- サプライチェーン対策：モデル/データのハッシュ（SHA256）・サイズ検証、入手元の由来ログを保持。

## 11. 制約・リスク
- 長文文脈依存が強い場合の性能劣化（要約/RAGで緩和）。
- 日本語口語表現での誤解（追加SFTや評価で改善）。
- 量子化による品質低下（サイズとビット幅のトレードオフ評価）。
- 整形式制約デコードの速度低下（キャッシュや軽量スキーマで対応）。

## 12. マイルストーン/ロードマップ（例）
- M1: 最小プロト（7B量子化、JSON関数提案、手動評価）
- M2: 評価基盤整備（自動指標、ベンチシナリオ、ログ可視化）
- M3: 調整比較実験（LoRA/RAG/プロンプト、各モデル横断）
- M4: 安全性/サンドボックス/承認フロー強化
- M5: 最終レポート（KPI達成可否、推奨構成、限界と今後）

### 12.1 Exit Criteria
- M1 Exit: JSON妥当性≥99%、基本関数群の正確性≥85%、P95レイテンシ≤目標+20%。
- M2 Exit: 自動評価一式・ストレス評価・ダッシュボード可視化が完了。
- M3 Exit: 量子化/LoRA/RAG/プロンプトの比較レポート完了、推奨構成提示。
- M4 Exit: セキュリティ検証（SSRF/権限分離/サンドボックス）合格。

## 13. 環境要件
- 推論ランタイム：llama.cpp/Ollama/vLLM いずれか（環境に応じ選択）。
- Python 3.10+、主要ライブラリ（例）：`transformers`, `accelerate`, `peft`, `bitsandbytes`(任意), `llama-cpp-python`, `fastapi`/`litestar`, `pydantic`, `uvicorn`, `jsonschema`。
- ログ/評価：`pandas`, `numpy`, `scikit-learn`, `matplotlib`/`seaborn`（任意）。
- ベクタストア（任意）：`faiss` または軽量代替。

## 14. 付録
### 14.1 関数呼び出しスキーマ例（JSON Schema）
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "StructuredActions",
  "type": "object",
  "properties": {
    "actions": {
      "type": "array",
      "items": {
        "type": "object",
        "required": ["function", "arguments"],
        "properties": {
          "function": {"type": "string"},
          "arguments": {"type": "object"},
          "confidence": {"type": "number", "minimum": 0, "maximum": 1},
          "rationale": {"type": "string"},
          "risk": {"type": "string", "enum": ["low", "medium", "high"]}
        }
      }
    }
  },
  "required": ["actions"]
}
```

### 14.2 応答メッセージ構造（例）
```json
{
  "reply": "もちろん。ギルドまでご案内します。",
  "structured_actions": {
    "actions": [
      {
        "function": "npc_follow_player",
        "arguments": {"npc_id": "bartender_01", "player_id": "P123", "speed": "walk"},
        "confidence": 0.86,
        "rationale": "プレイヤーが案内を要求。会話履歴より酒場主が適任。",
        "risk": "low"
      }
    ]
  }
}
```

### 14.3 評価ログ行（JSONL例）
```json
{"session_id":"s1","turn":3,"latency_ms":612,"json_valid":true,"tool_exact_match":true,"hallucinated":false}
```

---
最終的な推奨構成は、評価に基づき「モデル×量子化×プロンプト×RAG/LoRA」組合せで選定する。まずは7B/8B量子化＋整形式出力拘束＋最小RAGから開始し、KPI未達項目に対してLoRAやモデル変更を検討する。

